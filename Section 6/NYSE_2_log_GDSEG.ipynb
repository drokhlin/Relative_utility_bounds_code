{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This notebook computes optimal portfolio weights for NYSE_2 dataset in the case of logarithmic utility.\n",
    "The results for 30 experiments of the GDSEG algorithm are written to the file log_opt_portf_NYSE_2.txt\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(11178, 19)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       ahp    alcoa    amerb     coke      dow   dupont     ford       ge  \\\n0  1.01515  1.02765  1.04183  1.00637  1.00847  1.01983  1.00000  1.00000   \n1  1.01493  1.04036  0.98905  1.00475  1.00840  1.00833  1.00157  1.02187   \n2  1.00000  0.97629  0.97786  0.98583  0.99722  0.99449  0.98116  0.97860   \n3  1.02451  1.00662  1.02642  1.01917  0.99443  1.00693  1.02720  1.00795   \n4  1.03100  0.98465  1.00368  1.00313  1.02801  1.00413  1.04361  1.00394   \n\n        gm       hp      ibm    inger      jnj    kimbc    merck      mmm  \\\n0  1.01026  1.01935  1.00429  1.01357  0.99683  1.05340  1.03148  1.03377   \n1  0.99746  1.01266  0.99573  1.00446  1.00318  1.00461  1.00898  1.00251   \n2  0.98219  0.98125  0.98571  0.99556  0.95873  0.98165  0.98043  0.95990   \n3  0.98705  1.00637  1.01522  1.00000  1.01325  0.98131  1.01089  1.03655   \n4  1.00525  1.03165  1.02427  1.01563  1.00654  1.02381  1.01077  0.99496   \n\n    morris    pandg   schlum  \n0  1.01495  1.00775  1.01176  \n1  1.00000  1.00192  1.01938  \n2  0.97218  0.98656  0.97338  \n3  0.99663  1.00778  1.00000  \n4  0.98649  1.01158  1.01563  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ahp</th>\n      <th>alcoa</th>\n      <th>amerb</th>\n      <th>coke</th>\n      <th>dow</th>\n      <th>dupont</th>\n      <th>ford</th>\n      <th>ge</th>\n      <th>gm</th>\n      <th>hp</th>\n      <th>ibm</th>\n      <th>inger</th>\n      <th>jnj</th>\n      <th>kimbc</th>\n      <th>merck</th>\n      <th>mmm</th>\n      <th>morris</th>\n      <th>pandg</th>\n      <th>schlum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.01515</td>\n      <td>1.02765</td>\n      <td>1.04183</td>\n      <td>1.00637</td>\n      <td>1.00847</td>\n      <td>1.01983</td>\n      <td>1.00000</td>\n      <td>1.00000</td>\n      <td>1.01026</td>\n      <td>1.01935</td>\n      <td>1.00429</td>\n      <td>1.01357</td>\n      <td>0.99683</td>\n      <td>1.05340</td>\n      <td>1.03148</td>\n      <td>1.03377</td>\n      <td>1.01495</td>\n      <td>1.00775</td>\n      <td>1.01176</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.01493</td>\n      <td>1.04036</td>\n      <td>0.98905</td>\n      <td>1.00475</td>\n      <td>1.00840</td>\n      <td>1.00833</td>\n      <td>1.00157</td>\n      <td>1.02187</td>\n      <td>0.99746</td>\n      <td>1.01266</td>\n      <td>0.99573</td>\n      <td>1.00446</td>\n      <td>1.00318</td>\n      <td>1.00461</td>\n      <td>1.00898</td>\n      <td>1.00251</td>\n      <td>1.00000</td>\n      <td>1.00192</td>\n      <td>1.01938</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.00000</td>\n      <td>0.97629</td>\n      <td>0.97786</td>\n      <td>0.98583</td>\n      <td>0.99722</td>\n      <td>0.99449</td>\n      <td>0.98116</td>\n      <td>0.97860</td>\n      <td>0.98219</td>\n      <td>0.98125</td>\n      <td>0.98571</td>\n      <td>0.99556</td>\n      <td>0.95873</td>\n      <td>0.98165</td>\n      <td>0.98043</td>\n      <td>0.95990</td>\n      <td>0.97218</td>\n      <td>0.98656</td>\n      <td>0.97338</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.02451</td>\n      <td>1.00662</td>\n      <td>1.02642</td>\n      <td>1.01917</td>\n      <td>0.99443</td>\n      <td>1.00693</td>\n      <td>1.02720</td>\n      <td>1.00795</td>\n      <td>0.98705</td>\n      <td>1.00637</td>\n      <td>1.01522</td>\n      <td>1.00000</td>\n      <td>1.01325</td>\n      <td>0.98131</td>\n      <td>1.01089</td>\n      <td>1.03655</td>\n      <td>0.99663</td>\n      <td>1.00778</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.03100</td>\n      <td>0.98465</td>\n      <td>1.00368</td>\n      <td>1.00313</td>\n      <td>1.02801</td>\n      <td>1.00413</td>\n      <td>1.04361</td>\n      <td>1.00394</td>\n      <td>1.00525</td>\n      <td>1.03165</td>\n      <td>1.02427</td>\n      <td>1.01563</td>\n      <td>1.00654</td>\n      <td>1.02381</td>\n      <td>1.01077</td>\n      <td>0.99496</td>\n      <td>0.98649</td>\n      <td>1.01158</td>\n      <td>1.01563</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# Importing NYSE_2 dataset\n",
    "stocks=pd.read_csv('NYSE_2.csv')\n",
    "print(stocks.shape)\n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r: array for stock returns\n",
    "N=stocks.shape[0]\n",
    "d=stocks.shape[1]\n",
    "r=np.zeros((N,d))\n",
    "r=stocks.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GDSEG(U,R,n_attempts=10**4,threshold=1/10**10):\n",
    "    \"\"\" Greedy doubly stochastic exponentiated graient algorithm (GDSEG)\n",
    "    U: empirical utility, power or logarithmic \n",
    "    R: array of stock pirces\n",
    "    The function returns the optimal oprtfolio weights: w_old, the optimal value of the objective function: U(w_old,R), and the number of iterations: i\n",
    "    \"\"\"\n",
    "    N=R.shape[0]\n",
    "    d=R.shape[1]\n",
    "    w_old=np.ones(d)/d\n",
    "    w_new=np.zeros(d)\n",
    "    attempt=0\n",
    "    i=0\n",
    "    while attempt<=n_attempts:\n",
    "        i+=1\n",
    "        k=np.random.randint(0,N)\n",
    "        eta=np.random.rand()\n",
    "        a=[w_old[j]*np.exp(eta*R[k,j]/(np.dot(w_old,R[k,:]))**(1-alpha)) for j in range(d)]\n",
    "        w_new=a/np.sum(a)\n",
    "        attempt+=1\n",
    "        if U(w_new,R)>U(w_old,R)+threshold:\n",
    "            w_old=w_new\n",
    "            attempt=0\n",
    "        #if i%10000==0: print(s,i,100*w_old,U(w_old,R),eta)\n",
    "    return w_old, U(w_old,R), i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def U(nu,r):\n",
    "    \"\"\" Empirical utility, power (0<alpha<=1) or logarithmic (alpha=0) \"\"\"\n",
    "    if alpha==0:\n",
    "        return np.mean(np.log(np.dot(r[0:N,:],nu)))\n",
    "    else:\n",
    "        return np.mean(np.dot(r[0:N,:],nu)**alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "GDSEG experiment: 0 Number of iterations: 76609.0\nGDSEG experiment: 1 Number of iterations: 49354.0\nGDSEG experiment: 2 Number of iterations: 69340.0\nGDSEG experiment: 3 Number of iterations: 109417.0\nGDSEG experiment: 4 Number of iterations: 48305.0\nGDSEG experiment: 5 Number of iterations: 76294.0\nGDSEG experiment: 6 Number of iterations: 76579.0\nGDSEG experiment: 7 Number of iterations: 73420.0\nGDSEG experiment: 8 Number of iterations: 58426.0\nGDSEG experiment: 9 Number of iterations: 69659.0\nGDSEG experiment: 10 Number of iterations: 88821.0\nGDSEG experiment: 11 Number of iterations: 62463.0\nGDSEG experiment: 12 Number of iterations: 98641.0\nGDSEG experiment: 13 Number of iterations: 57029.0\nGDSEG experiment: 14 Number of iterations: 56517.0\nGDSEG experiment: 15 Number of iterations: 101258.0\nGDSEG experiment: 16 Number of iterations: 76068.0\nGDSEG experiment: 17 Number of iterations: 61866.0\nGDSEG experiment: 18 Number of iterations: 86395.0\nGDSEG experiment: 19 Number of iterations: 114030.0\nGDSEG experiment: 20 Number of iterations: 54420.0\nGDSEG experiment: 21 Number of iterations: 76966.0\nGDSEG experiment: 22 Number of iterations: 49596.0\nGDSEG experiment: 23 Number of iterations: 110033.0\nGDSEG experiment: 24 Number of iterations: 75819.0\nGDSEG experiment: 25 Number of iterations: 68353.0\nGDSEG experiment: 26 Number of iterations: 73171.0\nGDSEG experiment: 27 Number of iterations: 73953.0\nGDSEG experiment: 28 Number of iterations: 55063.0\nGDSEG experiment: 29 Number of iterations: 56148.0\n"
    }
   ],
   "source": [
    "# Computation of optimal portfolios\n",
    "n_experiments=30\n",
    "alpha=0.0\n",
    "opt_portf=np.zeros((n_experiments,d))\n",
    "opt_val=np.zeros(n_experiments)\n",
    "n_iter=np.zeros(n_experiments)\n",
    "f=open('log_opt_portf_NYSE_2.txt','ab')\n",
    "for s in range(n_experiments):\n",
    "    np.random.seed(1+s)\n",
    "    opt_portf[s,:], opt_val[s], n_iter[s]  = GDSEG(U,r)\n",
    "    print('GDSEG experiment:',s,'Number of iterations:',n_iter[s])\n",
    "    np.savetxt(f,opt_portf[s,:].reshape(1,d))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Average number of iterations 73467.1\n"
    }
   ],
   "source": [
    "print('Average number of iterations',n_iter.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}